{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f226ff76-6629-431a-81f5-d662a0fcb073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original train shape: (1460, 81)\n",
      "Original test shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#import the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"\\nOriginal train shape: {train_df.shape}\")\n",
    "print(f\"Original test shape: {test_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ea2f-7a6c-43af-89b2-9779f30ea56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0c51da-9c2f-46db-97a0-75b63581068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (2919, 80)\n"
     ]
    }
   ],
   "source": [
    "# Save target and IDs\n",
    "y_train = train_df['SalePrice']\n",
    "train_df = train_df.drop('SalePrice', axis=1)\n",
    "test_ids = test_df['Id']\n",
    "\n",
    "# Combine for preprocessing\n",
    "all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "print(f\"Combined data shape: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e5f016-467d-494e-a16d-d46062b7b647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HANDLING MISSING VALUES\n",
      "============================================================\n",
      "Missing values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Categorical: NaN means \"None\"\n",
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "             'MasVnrType']\n",
    "for col in none_cols:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "# Numerical: NaN means 0\n",
    "zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', \n",
    "             'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', \n",
    "             'BsmtHalfBath', 'MasVnrArea']\n",
    "for col in zero_cols:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "# LotFrontage: Fill with median by neighborhood\n",
    "if 'LotFrontage' in all_data.columns:\n",
    "    all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill remaining with mode\n",
    "for col in all_data.columns:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        if all_data[col].dtype == 'object':\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "        else:\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "print(f\"Missing values after cleaning: {all_data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2562087-c349-46fd-8d81-9cf5d94b0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING\n",
      "============================================================\n",
      "Created features: TotalSF, TotalBath, HouseAge, RemodAge, and binary indicators\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Total square footage\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "# Total bathrooms\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + 0.5 * all_data['HalfBath'] + \n",
    "                          all_data['BsmtFullBath'] + 0.5 * all_data['BsmtHalfBath'])\n",
    "\n",
    "# House age\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['RemodAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "\n",
    "# Binary features\n",
    "all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)\n",
    "all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)\n",
    "all_data['HasBsmt'] = (all_data['TotalBsmtSF'] > 0).astype(int)\n",
    "all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)\n",
    "all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0).astype(int)\n",
    "\n",
    "print(\"Created features: TotalSF, TotalBath, HouseAge, RemodAge, and binary indicators\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd00fdb-b56f-4cf9-9180-e09b7344fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ENCODING CATEGORICAL VARIABLES\n",
      "============================================================\n",
      "Shape after encoding: (2919, 268)\n",
      "Total features: 268\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Drop Id column\n",
    "all_data = all_data.drop('Id', axis=1)\n",
    "\n",
    "# One-hot encode\n",
    "categorical_cols = all_data.select_dtypes(include=['object']).columns\n",
    "all_data = pd.get_dummies(all_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"Shape after encoding: {all_data.shape}\")\n",
    "print(f\"Total features: {all_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b749fa4b-4b26-474d-80e8-b36356d0bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 4 outliers\n",
      "\n",
      "Final train shape: (1456, 268)\n",
      "Final test shape: (1459, 268)\n"
     ]
    }
   ],
   "source": [
    "train_processed = all_data[:len(train_df)]\n",
    "test_processed = all_data[len(train_df):]\n",
    "\n",
    "# Remove outliers\n",
    "outliers = train_processed[(train_processed['GrLivArea'] > 4000)].index\n",
    "if len(outliers) > 0:\n",
    "    train_processed = train_processed.drop(outliers)\n",
    "    y_train = y_train.drop(outliers)\n",
    "    print(f\"\\nRemoved {len(outliers)} outliers\")\n",
    "\n",
    "# Prepare final datasets\n",
    "X_train = train_processed\n",
    "y_train = np.log1p(y_train)  # Log transform target for better performance\n",
    "\n",
    "print(f\"\\nFinal train shape: {X_train.shape}\")\n",
    "print(f\"Final test shape: {test_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db37c2e-7180-4d7d-a45a-adede03b7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SPLITTING DATA FOR VALIDATION\n",
      "============================================================\n",
      "Training set: (1164, 268)\n",
      "Validation set: (292, 268)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SPLITTING DATA FOR VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_tr.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a010912-75fa-4322-a292-b3a3c6a2c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING MODELS\n",
      "============================================================\n",
      "\n",
      "Training Linear Regression...\n",
      "  RMSE: 0.1300\n",
      "  R¬≤ Score: 0.8930\n",
      "  MAE: 0.0881\n",
      "\n",
      "Training Ridge Regression...\n",
      "  RMSE: 0.1293\n",
      "  R¬≤ Score: 0.8942\n",
      "  MAE: 0.0874\n",
      "\n",
      "Training Lasso Regression...\n",
      "  RMSE: 0.1256\n",
      "  R¬≤ Score: 0.9002\n",
      "  MAE: 0.0847\n",
      "\n",
      "Training Random Forest...\n",
      "  RMSE: 0.1442\n",
      "  R¬≤ Score: 0.8684\n",
      "  MAE: 0.0970\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  RMSE: 0.1339\n",
      "  R¬≤ Score: 0.8864\n",
      "  MAE: 0.0924\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(test_processed)\n",
    "\n",
    "# ============================================\n",
    "# STEP 8: Train Multiple Models\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=10),\n",
    "    'Lasso Regression': Lasso(alpha=0.001, max_iter=10000),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_tr_scaled, y_tr)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    \n",
    "    results[name] = {'RMSE': rmse, 'R2': r2, 'MAE': mae, 'model': model}\n",
    "    \n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1171e161-fb3b-4e5d-aaa5-ded22a6684c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL COMPARISON\n",
      "============================================================\n",
      "            Model     RMSE       R¬≤      MAE\n",
      " Lasso Regression 0.125552 0.900193 0.084727\n",
      " Ridge Regression 0.129287 0.894166 0.087409\n",
      "Linear Regression 0.129995 0.893005 0.088145\n",
      "Gradient Boosting 0.133921 0.886444 0.092401\n",
      "    Random Forest 0.144190 0.868362 0.097021\n",
      "\n",
      "üèÜ Best Model: Lasso Regression\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'RMSE': [results[m]['RMSE'] for m in results.keys()],\n",
    "    'R¬≤': [results[m]['R2'] for m in results.keys()],\n",
    "    'MAE': [results[m]['MAE'] for m in results.keys()]\n",
    "})\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08164aef-1c4c-49f9-98c1-707788069cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MAKING PREDICTIONS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retrain on full training data\n",
    "best_model.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "test_predictions = np.expm1(test_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f230a4-4e61-4c87-aae5-4df513284e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions saved to 'submission.csv'\n",
      "\n",
      "Sample predictions:\n",
      "     Id      SalePrice\n",
      "0  1461  119832.961635\n",
      "1  1462  154393.364686\n",
      "2  1463  180584.702633\n",
      "3  1464  199502.582029\n",
      "4  1465  194821.135555\n",
      "5  1466  171597.223133\n",
      "6  1467  180924.475161\n",
      "7  1468  163755.070880\n",
      "8  1469  195668.725512\n",
      "9  1470  119001.910842\n",
      "\n",
      "============================================================\n",
      "MODEL BUILDING COMPLETE!\n",
      "============================================================\n",
      "Best Model: Lasso Regression\n",
      "Best RMSE: 0.1256\n",
      "Best R¬≤ Score: 0.9002\n",
      "\n",
      "Submission file ready for Kaggle!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\n‚úÖ Predictions saved to 'submission.csv'\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL BUILDING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best RMSE: {results[best_model_name]['RMSE']:.4f}\")\n",
    "print(f\"Best R¬≤ Score: {results[best_model_name]['R2']:.4f}\")\n",
    "print(\"\\nSubmission file ready for Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815ac040-f379-43bf-901f-1109cad5c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING THE MODEL\n",
      "============================================================\n",
      "‚úÖ Model saved as 'sa_house_price_model.joblib'\n",
      "‚úÖ Best model saved separately as 'best_model_only.joblib'\n",
      "\n",
      "üìä Model Details:\n",
      "   - Model Type: Lasso\n",
      "   - Features: 268\n",
      "   - Training Samples: 1456\n",
      "   - Validation RMSE: 0.1256\n",
      "   - Validation R¬≤: 0.9002\n",
      "‚úÖ Model verification: Load successful!\n",
      "‚úÖ Package contains: ['best_model', 'scaler', 'feature_names', 'preprocessing_info', 'performance']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SAVE THE TRAINED MODEL\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING THE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a model package with everything needed for predictions\n",
    "model_package = {\n",
    "    'best_model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'preprocessing_info': {\n",
    "        'target_log_transformed': True,  # Remember we used log transform\n",
    "        'outliers_removed': True,\n",
    "        'training_date': pd.Timestamp.now().isoformat()\n",
    "    },\n",
    "    'performance': {\n",
    "        'best_model_name': best_model_name,\n",
    "        'rmse': results[best_model_name]['RMSE'],\n",
    "        'r2_score': results[best_model_name]['R2']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the complete package\n",
    "joblib.dump(model_package, 'sa_house_price_model.joblib')\n",
    "print(\"‚úÖ Model saved as 'sa_house_price_model.joblib'\")\n",
    "\n",
    "# Also save just the model separately for quick access\n",
    "joblib.dump(best_model, 'best_model_only.joblib')\n",
    "print(\"‚úÖ Best model saved separately as 'best_model_only.joblib'\")\n",
    "\n",
    "# Print model details\n",
    "print(f\"\\nüìä Model Details:\")\n",
    "print(f\"   - Model Type: {type(best_model).__name__}\")\n",
    "print(f\"   - Features: {len(X_train.columns)}\")\n",
    "print(f\"   - Training Samples: {X_train.shape[0]}\")\n",
    "print(f\"   - Validation RMSE: {results[best_model_name]['RMSE']:.4f}\")\n",
    "print(f\"   - Validation R¬≤: {results[best_model_name]['R2']:.4f}\")\n",
    "\n",
    "# Verify the save worked\n",
    "try:\n",
    "    loaded_package = joblib.load('sa_house_price_model.joblib')\n",
    "    print(\"‚úÖ Model verification: Load successful!\")\n",
    "    print(f\"‚úÖ Package contains: {list(loaded_package.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error verifying model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d6ab7-0d2a-40db-a0a7-79271699b90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538718e-7dae-4c8d-a2b4-1e7cb1e41c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
